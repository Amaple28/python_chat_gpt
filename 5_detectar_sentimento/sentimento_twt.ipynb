{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "<empty message>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 28\u001B[0m\n\u001B[0;32m     26\u001B[0m openai\u001B[39m.\u001B[39mapi_key \u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mKEY\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m     27\u001B[0m prompt \u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mResponda em ÚNICA palavra, sendo positivo, negativo ou neutro o sentimento do seguinte texto: \u001B[39m\u001B[39m\"\u001B[39m\u001B[39m+\u001B[39m tweet_limpo\n\u001B[1;32m---> 28\u001B[0m response \u001B[39m=\u001B[39m openai\u001B[39m.\u001B[39;49mCompletion\u001B[39m.\u001B[39;49mcreate(\n\u001B[0;32m     29\u001B[0m     model\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mtext-davinci-003\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[0;32m     30\u001B[0m     prompt\u001B[39m=\u001B[39;49m prompt,\n\u001B[0;32m     31\u001B[0m     temperature\u001B[39m=\u001B[39;49m \u001B[39m0.7\u001B[39;49m,\n\u001B[0;32m     32\u001B[0m     max_tokens\u001B[39m=\u001B[39;49m \u001B[39m10\u001B[39;49m,\n\u001B[0;32m     33\u001B[0m     n\u001B[39m=\u001B[39;49m\u001B[39m1\u001B[39;49m, \n\u001B[0;32m     34\u001B[0m     stop\u001B[39m=\u001B[39;49m\u001B[39mNone\u001B[39;49;00m \n\u001B[0;32m     35\u001B[0m )\n\u001B[0;32m     37\u001B[0m \u001B[39m# Passo 1: Pegando response a resposta \u001B[39;00m\n\u001B[0;32m     38\u001B[0m choices \u001B[39m=\u001B[39m response[\u001B[39m\"\u001B[39m\u001B[39mchoices\u001B[39m\u001B[39m\"\u001B[39m][\u001B[39m0\u001B[39m] \n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\completion.py:25\u001B[0m, in \u001B[0;36mCompletion.create\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[39mwhile\u001B[39;00m \u001B[39mTrue\u001B[39;00m:\n\u001B[0;32m     24\u001B[0m     \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m---> 25\u001B[0m         \u001B[39mreturn\u001B[39;00m \u001B[39msuper\u001B[39;49m()\u001B[39m.\u001B[39;49mcreate(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[0;32m     26\u001B[0m     \u001B[39mexcept\u001B[39;00m TryAgain \u001B[39mas\u001B[39;00m e:\n\u001B[0;32m     27\u001B[0m         \u001B[39mif\u001B[39;00m timeout \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39mand\u001B[39;00m time\u001B[39m.\u001B[39mtime() \u001B[39m>\u001B[39m start \u001B[39m+\u001B[39m timeout:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[39m@classmethod\u001B[39m\n\u001B[0;32m    128\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mcreate\u001B[39m(\n\u001B[0;32m    129\u001B[0m     \u001B[39mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    136\u001B[0m     \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mparams,\n\u001B[0;32m    137\u001B[0m ):\n\u001B[0;32m    138\u001B[0m     (\n\u001B[0;32m    139\u001B[0m         deployment_id,\n\u001B[0;32m    140\u001B[0m         engine,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mparams\n\u001B[0;32m    151\u001B[0m     )\n\u001B[1;32m--> 153\u001B[0m     response, _, api_key \u001B[39m=\u001B[39m requestor\u001B[39m.\u001B[39;49mrequest(\n\u001B[0;32m    154\u001B[0m         \u001B[39m\"\u001B[39;49m\u001B[39mpost\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[0;32m    155\u001B[0m         url,\n\u001B[0;32m    156\u001B[0m         params\u001B[39m=\u001B[39;49mparams,\n\u001B[0;32m    157\u001B[0m         headers\u001B[39m=\u001B[39;49mheaders,\n\u001B[0;32m    158\u001B[0m         stream\u001B[39m=\u001B[39;49mstream,\n\u001B[0;32m    159\u001B[0m         request_id\u001B[39m=\u001B[39;49mrequest_id,\n\u001B[0;32m    160\u001B[0m         request_timeout\u001B[39m=\u001B[39;49mrequest_timeout,\n\u001B[0;32m    161\u001B[0m     )\n\u001B[0;32m    163\u001B[0m     \u001B[39mif\u001B[39;00m stream:\n\u001B[0;32m    164\u001B[0m         \u001B[39m# must be an iterator\u001B[39;00m\n\u001B[0;32m    165\u001B[0m         \u001B[39massert\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:230\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mrequest\u001B[39m(\n\u001B[0;32m    210\u001B[0m     \u001B[39mself\u001B[39m,\n\u001B[0;32m    211\u001B[0m     method,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    218\u001B[0m     request_timeout: Optional[Union[\u001B[39mfloat\u001B[39m, Tuple[\u001B[39mfloat\u001B[39m, \u001B[39mfloat\u001B[39m]]] \u001B[39m=\u001B[39m \u001B[39mNone\u001B[39;00m,\n\u001B[0;32m    219\u001B[0m ) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[39mbool\u001B[39m, \u001B[39mstr\u001B[39m]:\n\u001B[0;32m    220\u001B[0m     result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mrequest_raw(\n\u001B[0;32m    221\u001B[0m         method\u001B[39m.\u001B[39mlower(),\n\u001B[0;32m    222\u001B[0m         url,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    228\u001B[0m         request_timeout\u001B[39m=\u001B[39mrequest_timeout,\n\u001B[0;32m    229\u001B[0m     )\n\u001B[1;32m--> 230\u001B[0m     resp, got_stream \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_interpret_response(result, stream)\n\u001B[0;32m    231\u001B[0m     \u001B[39mreturn\u001B[39;00m resp, got_stream, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mapi_key\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:624\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[1;34m(self, result, stream)\u001B[0m\n\u001B[0;32m    616\u001B[0m     \u001B[39mreturn\u001B[39;00m (\n\u001B[0;32m    617\u001B[0m         \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_interpret_response_line(\n\u001B[0;32m    618\u001B[0m             line, result\u001B[39m.\u001B[39mstatus_code, result\u001B[39m.\u001B[39mheaders, stream\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m\n\u001B[0;32m    619\u001B[0m         )\n\u001B[0;32m    620\u001B[0m         \u001B[39mfor\u001B[39;00m line \u001B[39min\u001B[39;00m parse_stream(result\u001B[39m.\u001B[39miter_lines())\n\u001B[0;32m    621\u001B[0m     ), \u001B[39mTrue\u001B[39;00m\n\u001B[0;32m    622\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m    623\u001B[0m     \u001B[39mreturn\u001B[39;00m (\n\u001B[1;32m--> 624\u001B[0m         \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_interpret_response_line(\n\u001B[0;32m    625\u001B[0m             result\u001B[39m.\u001B[39;49mcontent\u001B[39m.\u001B[39;49mdecode(\u001B[39m\"\u001B[39;49m\u001B[39mutf-8\u001B[39;49m\u001B[39m\"\u001B[39;49m),\n\u001B[0;32m    626\u001B[0m             result\u001B[39m.\u001B[39;49mstatus_code,\n\u001B[0;32m    627\u001B[0m             result\u001B[39m.\u001B[39;49mheaders,\n\u001B[0;32m    628\u001B[0m             stream\u001B[39m=\u001B[39;49m\u001B[39mFalse\u001B[39;49;00m,\n\u001B[0;32m    629\u001B[0m         ),\n\u001B[0;32m    630\u001B[0m         \u001B[39mFalse\u001B[39;00m,\n\u001B[0;32m    631\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:687\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[1;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[0;32m    685\u001B[0m stream_error \u001B[39m=\u001B[39m stream \u001B[39mand\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39merror\u001B[39m\u001B[39m\"\u001B[39m \u001B[39min\u001B[39;00m resp\u001B[39m.\u001B[39mdata\n\u001B[0;32m    686\u001B[0m \u001B[39mif\u001B[39;00m stream_error \u001B[39mor\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39m200\u001B[39m \u001B[39m<\u001B[39m\u001B[39m=\u001B[39m rcode \u001B[39m<\u001B[39m \u001B[39m300\u001B[39m:\n\u001B[1;32m--> 687\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandle_error_response(\n\u001B[0;32m    688\u001B[0m         rbody, rcode, resp\u001B[39m.\u001B[39mdata, rheaders, stream_error\u001B[39m=\u001B[39mstream_error\n\u001B[0;32m    689\u001B[0m     )\n\u001B[0;32m    690\u001B[0m \u001B[39mreturn\u001B[39;00m resp\n",
      "\u001B[1;31mAuthenticationError\u001B[0m: <empty message>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "import json\n",
    "import string\n",
    "\n",
    "# Vamos diminuir a quantidade de linhas!!!!!!!\n",
    "df = pd.read_parquet(r'dados_twt.parquet')\n",
    "df = df.head(5) \n",
    "\n",
    "# Obtenha os nomes das colunas do DataFrame original\n",
    "columns = df.columns.tolist()\n",
    "# Adicionando nova coluna\n",
    "columns.append('sentimento_gpt') \n",
    "df_coleta = pd.DataFrame(columns=columns)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tweet = row['text']\n",
    "\n",
    "    # Forma regex para excluir o inicio do rt\n",
    "    padrao_rt = r'rt @\\w+:'  \n",
    "    # Excluindo a parte do rt\n",
    "    tweet_limpo = re.sub(padrao_rt, '', tweet).strip() \n",
    "    \n",
    "    # API_OPENAI\n",
    "    openai.api_key = \"KEY\"\n",
    "    prompt = \"Responda em ÚNICA palavra, sendo positivo, negativo ou neutro o sentimento do seguinte texto: \"+ tweet_limpo\n",
    "    response = openai.Completion.create(\n",
    "        model=\"davinci-002\",\n",
    "        prompt= prompt,\n",
    "        temperature= 0.7,\n",
    "        max_tokens= 10,\n",
    "        n=1, \n",
    "        stop=None \n",
    "    )\n",
    "    \n",
    "    # Passo 1: Pegando response a resposta \n",
    "    choices = response[\"choices\"][0] \n",
    "    data_dict = json.loads(str(choices))\n",
    "    resposta = data_dict['text']\n",
    "\n",
    "    # Passo 2: Remove pontos e vírgulas\n",
    "    tabela_punctuation = str.maketrans('', '', string.punctuation)\n",
    "    frase_sem_pontuacao = resposta.translate(tabela_punctuation)\n",
    "\n",
    "    # Passo 3: Transformando a frase em uma lista com base no espaço entre as palavras\n",
    "    tokens = frase_sem_pontuacao.strip().split()\n",
    "\n",
    "    # Passo 4: Seleção de palavras-chave\n",
    "    palavras_chave = ['neutro', 'positivo', 'negativo']\n",
    "    palavras_selecionadas = [token for token in tokens if token.lower() in palavras_chave]\n",
    "    \n",
    "    # Passo 5: Juntar as palavras selecionadas\n",
    "    sentimento_gpt = ''.join(palavras_selecionadas)\n",
    "    \n",
    "    df_coleta.loc[len(df_coleta)] = [tweet, row['sentimento_google'], row['toxicity_score_google'], row['senti'], row['nota_senticnet_scaler'], sentimento_gpt]\n",
    "\n",
    "# Tirando o score\n",
    "df_final = df_coleta.drop(df.columns[[2,4]], axis=1)\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Vamos diminuir a quantidade de linhas!!!!!!!\n",
    "df = pd.read_parquet(r'.\\data\\dados_twt.parquet')\n",
    "df = df.head(5) \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
